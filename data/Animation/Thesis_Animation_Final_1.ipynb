{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JQreaP9izPeZ"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from numpy import random\n",
        "class UAVenv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "    # Fixed Input Parameters\n",
        "    NUM_USER = 100   # Number of ground user\n",
        "    NUM_UAV = 5   # Number of UAV\n",
        "    MAX_USER_COVER_EACH_UAV= 20  # Maximum Capacity for each UAV to cover users\n",
        "    COVERAGE_XY = 1000\n",
        "    grid_space = 100\n",
        "    GRID_SIZE = int(COVERAGE_XY / grid_space)\n",
        "\n",
        "    UAV_HEIGHT = 350\n",
        "    THETA = 60 * math.pi / 180 # In radian\n",
        "\n",
        "    ## Polar to Cartesian and vice versa\n",
        "    def pol2cart(r,theta):\n",
        "        x = r * np.cos(theta)\n",
        "        y = r * np.sin(theta)\n",
        "        return (x, y)\n",
        "\n",
        "    def cart2pol(x, y):\n",
        "        theta = np.arctan2(y, x)\n",
        "        r = np.hypot(x, y)\n",
        "        return r, theta\n",
        "\n",
        "    ############################################################################\n",
        "    ##     User Distribution // Hotspots with Uniform Distribution      ##\n",
        "    ############################################################################\n",
        "\n",
        "    #SEED = 1\n",
        "    #random.seed(SEED)\n",
        "\n",
        "    #HOTSPOTS = np.array([[300, 300], [800, 800], [300, 800], [800, 300]])\n",
        "\n",
        "    #USER_DIS = [15, 20, 30, 25]\n",
        "    #USER_LOC = np.zeros((sum(USER_DIS) + 10, 3)) # +10 for 10 additional random users\n",
        "\n",
        "    #start_index = 0\n",
        "    #for i in range(len(HOTSPOTS)):\n",
        "        #for j in range(start_index, start_index + USER_DIS[i]):\n",
        "            #temp_loc_r = random.uniform(-(1/5)*COVERAGE_XY, (1/5)*COVERAGE_XY)\n",
        "            #temp_loc_theta = random.uniform(0, 2*math.pi)\n",
        "            #temp_loc = pol2cart(temp_loc_r, temp_loc_theta)\n",
        "            #temp_loc_1, temp_loc_2 = temp_loc\n",
        "            #temp_loc_1 = temp_loc_1 + HOTSPOTS[i, 0]\n",
        "            #temp_loc_2 = temp_loc_2 + HOTSPOTS[i, 1]\n",
        "            #USER_LOC[j, :] = [temp_loc_1, temp_loc_2, i]\n",
        "        #start_index += USER_DIS[i]\n",
        "\n",
        "    #temp_loc = np.random.uniform(low=0, high=COVERAGE_XY, size=(10, 2))\n",
        "    #USER_LOC[start_index:start_index+10, :2] = temp_loc\n",
        "    #USER_LOC[start_index:start_index+10, 2] = 4 # Assign region 4 to scattered users\n",
        "    #np.savetxt('UserLocationNew.txt', USER_LOC, fmt='%.3e', delimiter=' ', newline='\\n')\n",
        "\n",
        "    #print(USER_LOC)\n",
        "    # Plot users with different colors for different regions\n",
        "    #fig = plt.figure(figsize=(6, 6), dpi=200)\n",
        "    #gs = GridSpec(1, 1, figure=fig)\n",
        "    #ax = fig.add_subplot(gs[0:1, 0:1])\n",
        "    #ax.cla()\n",
        "    #for i in range(USER_LOC.shape[0]):\n",
        "        #if USER_LOC[i, 2] == 0:\n",
        "            #co = '#CB4335'\n",
        "        #elif USER_LOC[i, 2] == 1:\n",
        "            #co = '#7D3C98'\n",
        "        #elif USER_LOC[i, 2] == 2:\n",
        "            #co = '#2E86C1'\n",
        "        #elif USER_LOC[i, 2] == 3:\n",
        "            #co = '#28B463'\n",
        "        #elif USER_LOC[i, 2] == 4:\n",
        "            #co = '#F1C40F'\n",
        "\n",
        "        #ax.scatter(USER_LOC[i, 0], USER_LOC[i, 1], c=co, marker='o')\n",
        "    USER_LOC = np.loadtxt('UserLocationNew.txt', delimiter=' ').astype(np.int64)\n",
        "\n",
        "    def __init__(self):\n",
        "        super(UAVenv, self).__init__()\n",
        "        # Five different action for the movement of each UAV\n",
        "        # 0 = Right, 1 = Left, 2 = straight, 3 = back, 4 = Hover\n",
        "        # Position of the UAV in space // X and Y pos\n",
        "        self.u_loc = self.USER_LOC\n",
        "        self.state = np.zeros((self.NUM_UAV, 4))\n",
        "        self.state[:,:2] = np.zeros((self.NUM_UAV, 2), dtype=np.int32)\n",
        "        self.state[:,2] = np.zeros((self.NUM_UAV,), dtype=np.float32)\n",
        "        self.state[:,3] = np.zeros((self.NUM_UAV,), dtype=np.float32)\n",
        "        self.flag = [0, 0, 0, 0, 0]\n",
        "        self.coverage_radius = self.UAV_HEIGHT * np.tan(self.THETA / 2)\n",
        "        self.uav_assigned_to_jammed = None\n",
        "\n",
        "\n",
        "    def step(self, action, reward, jammed_uav_index=None):\n",
        "        # Take the action\n",
        "        # Execution of one step within the environment\n",
        "        # Deal with out of boundaries conditions\n",
        "        isDone = False\n",
        "        # Calculate the distance of every users to the UAV BS and organize as a list\n",
        "\n",
        "        dist_u_uav = np.zeros(shape=(self.NUM_UAV, self.NUM_USER))\n",
        "\n",
        "        for i in range(self.NUM_UAV):\n",
        "            temp_x = self.state[i, 0]\n",
        "            temp_y = self.state[i, 1]\n",
        "            #print(\"Before action: \", (temp_x, temp_y))\n",
        "            # one step action\n",
        "            if action[i] == 0:\n",
        "                self.state[i, 0] = self.state[i, 0] + 1\n",
        "            elif action[i] == 1:\n",
        "                self.state[i, 0] = self.state[i, 0] - 1\n",
        "            elif action[i] == 2:\n",
        "                self.state[i, 1] = self.state[i, 1] + 1\n",
        "            elif action[i] == 3:\n",
        "                self.state[i, 1] = self.state[i, 1] - 1\n",
        "            elif action[i] == 4:\n",
        "                pass\n",
        "            else:\n",
        "                print(\"Error Action Value\")\n",
        "\n",
        "            # Take boundary condition into account // Individual flag for punishing the UAV\n",
        "            if self.state[i,0] < 0 or self.state[i,0] > self.GRID_SIZE or self.state[i, 1] < 0 or self.state[i,1] > self.GRID_SIZE:\n",
        "                self.state[i, 0] = temp_x\n",
        "                self.state[i, 1] = temp_y\n",
        "                self.flag[i] = 1     # Later penalize the reward value based on the flag\n",
        "            else:\n",
        "              self.flag[i] = 0\n",
        "\n",
        "            #print(\"After action: \", (self.state[i, 0], self.state[i, 1]))\n",
        "\n",
        "\n",
        "            # Calculation of the distance value for all UAV and User\n",
        "            for l in range(self.NUM_USER):\n",
        "                dist_u_uav[i, l] = math.sqrt((self.u_loc[l, 0] - (self.state[i, 0] * self.grid_space)) ** 2 + (self.u_loc[l, 1] -(self.state[i, 1] * self.grid_space)) ** 2)\n",
        "\n",
        "\n",
        "        ######################\n",
        "        ## Final Algorithm  ##\n",
        "        ######################\n",
        "\n",
        "        # User association to the UAV based on the distance value. First do a single sweep by all\n",
        "        # the Users to request to connect to the closest UAV After the first sweep is complete the UAV will admit a\n",
        "        # certain Number of Users based on capacity. In the second sweep the User will request to the UAV\n",
        "        # that is closest to it and UAV will admit the User if UAV has not reached its maximum capacity.\n",
        "\n",
        "        # Connection request is a np array matrix that contains UAV Number as row and\n",
        "        # User Number Connected to it on Columns and is stored in individual UAV to keep track of the\n",
        "        # User requesting to connect\n",
        "        # Initialize the connection_request table with zeros\n",
        "        connection_request = np.zeros(shape=(self.NUM_UAV, self.NUM_USER), dtype=\"int\")\n",
        "        for i in range(self.NUM_USER):\n",
        "            close_uav = np.argmin(dist_u_uav[:, i])\n",
        "            if dist_u_uav[close_uav, i] <= self.coverage_radius:\n",
        "                connection_request[close_uav, i] = 1\n",
        "\n",
        "        user_asso_flag = np.zeros((self.NUM_UAV, self.NUM_USER), dtype=\"int\")\n",
        "        uav_asso_count = np.zeros(self.NUM_UAV, dtype=\"int\")\n",
        "\n",
        "        for i in range(self.NUM_UAV):\n",
        "            if i == jammed_uav_index:\n",
        "                continue\n",
        "\n",
        "            temp_user = np.where(connection_request[i, :] == 1)\n",
        "            temp_user_distance = dist_u_uav[i, temp_user]\n",
        "            temp_user_sorted = np.argsort(temp_user_distance)\n",
        "            temp_user = np.array(temp_user)\n",
        "            temp_user_actual_idx = temp_user[0, temp_user_sorted]\n",
        "\n",
        "            for user_index in temp_user_actual_idx[0]:\n",
        "                if uav_asso_count[i] < self.MAX_USER_COVER_EACH_UAV:\n",
        "                    user_asso_flag[i, user_index] = 1\n",
        "                    uav_asso_count[i] += 1\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "        for j in range(self.NUM_USER):\n",
        "            if not np.any(user_asso_flag[:, j] != 0):\n",
        "                close_uav_id = dist_u_uav[:, j]\n",
        "                close_uav_id = [i[0] for i in sorted(enumerate(close_uav_id), key=lambda x: x[1])]\n",
        "                for close_id in close_uav_id:\n",
        "                    if close_id == jammed_uav_index:\n",
        "                        continue\n",
        "                    if dist_u_uav[close_id, j] <= self.coverage_radius:\n",
        "                        if np.sum(user_asso_flag[close_id]) < self.MAX_USER_COVER_EACH_UAV:\n",
        "                            uav_asso_count[close_id] += 1\n",
        "                            user_asso_flag[close_id, j] = 1\n",
        "                            break\n",
        "        if jammed_uav_index is not None:\n",
        "            # Exclude the jammed UAV and UAVs in transit when finding the UAV with the minimum users\n",
        "            valid_uav_indices = [i for i in range(self.NUM_UAV) if i != jammed_uav_index and self.state[i, 2] != 0]\n",
        "\n",
        "            # Check if the jammed UAV is covering more users than any other UAV\n",
        "            jammed_uav_users = uav_asso_count[jammed_uav_index]\n",
        "            min_users_other_uavs = np.min(uav_asso_count[valid_uav_indices])\n",
        "\n",
        "            if jammed_uav_users > min_users_other_uavs:\n",
        "                # Check if we already have a UAV assigned to handle the jammed UAV\n",
        "                if self.uav_assigned_to_jammed is None:\n",
        "                    print(\"Valid UAV indices:\", valid_uav_indices)  # Print the valid indices\n",
        "                    uav_with_min_users = valid_uav_indices[np.argmin(uav_asso_count[valid_uav_indices])]\n",
        "                    self.uav_assigned_to_jammed = uav_with_min_users\n",
        "                else:\n",
        "                    uav_with_min_users = self.uav_assigned_to_jammed\n",
        "\n",
        "                # Example positions\n",
        "                current_position = self.state[uav_with_min_users, :2].astype(int)\n",
        "                target_position = self.state[jammed_uav_index, :2].astype(int)\n",
        "                print(f\"Starting at position: {current_position}\")\n",
        "\n",
        "                if not np.array_equal(current_position, target_position):\n",
        "                    # Calculate direction vector\n",
        "                    direction_vector = target_position - current_position\n",
        "\n",
        "                    # Determine step direction in integer units\n",
        "                    step_x = int(np.sign(direction_vector[0]))\n",
        "                    step_y = int(np.sign(direction_vector[1]))\n",
        "\n",
        "                    # Move UAV by one step\n",
        "                    next_position = current_position + np.array([step_x, step_y])\n",
        "                    self.state[uav_with_min_users, :2] = next_position\n",
        "                    print(f\"Moving to position: {next_position}\")\n",
        "                else:\n",
        "                    self.uav_assigned_to_jammed = None  # Reset once the target is reached\n",
        "\n",
        "\n",
        "            # Re-associate users for the UAV that moved to the jammed UAV's position\n",
        "            connection_request[jammed_uav_index, :] = 0  # Clear previous connections of jammed UAV\n",
        "\n",
        "            for i in range(self.NUM_USER):\n",
        "                close_uav = np.argmin(dist_u_uav[:, i])\n",
        "                if dist_u_uav[close_uav, i] <= self.coverage_radius:\n",
        "                    connection_request[close_uav, i] = 1\n",
        "\n",
        "            uav_asso_count = np.zeros(self.NUM_UAV, dtype=\"int\")\n",
        "            user_asso_flag = np.zeros((self.NUM_UAV, self.NUM_USER), dtype=\"int\")\n",
        "\n",
        "            for i in range(self.NUM_UAV):\n",
        "                if i == jammed_uav_index:\n",
        "                    continue\n",
        "\n",
        "                temp_user = np.where(connection_request[i, :] == 1)\n",
        "                temp_user_distance = dist_u_uav[i, temp_user]\n",
        "                temp_user_sorted = np.argsort(temp_user_distance)\n",
        "                temp_user = np.array(temp_user)\n",
        "                temp_user_actual_idx = temp_user[0, temp_user_sorted]\n",
        "\n",
        "                for user_index in temp_user_actual_idx[0]:\n",
        "                    if uav_asso_count[i] < self.MAX_USER_COVER_EACH_UAV:\n",
        "                        user_asso_flag[i, user_index] = 1\n",
        "                        uav_asso_count[i] += 1\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "        for j in range(self.NUM_USER):\n",
        "            if not np.any(user_asso_flag[:, j] != 0):\n",
        "                close_uav_id = dist_u_uav[:, j]\n",
        "                close_uav_id = [i[0] for i in sorted(enumerate(close_uav_id), key=lambda x: x[1])]\n",
        "                for close_id in close_uav_id:\n",
        "                    if close_id == jammed_uav_index:\n",
        "                        continue\n",
        "                    if dist_u_uav[close_id, j] <= self.coverage_radius:\n",
        "                        if np.sum(user_asso_flag[close_id]) < self.MAX_USER_COVER_EACH_UAV:\n",
        "                            uav_asso_count[close_id] += 1\n",
        "                            user_asso_flag[close_id, j] = 1\n",
        "                            break\n",
        "\n",
        "        sum_user_assoc = np.sum(user_asso_flag, axis = 1)\n",
        "        self.state[:, 2] = sum_user_assoc / self.MAX_USER_COVER_EACH_UAV\n",
        "\n",
        "        overall_coverage_rate = np.sum(uav_asso_count) / self.NUM_USER\n",
        "        #print(overall_coverage_rate)\n",
        "        self.state[:, 3] = np.ones(self.NUM_UAV) * overall_coverage_rate\n",
        "\n",
        "\n",
        "        # Calculation of reward function\n",
        "        sum_user_assoc = np.sum(user_asso_flag, axis = 1)\n",
        "        sum_user_assoc_temp = np.copy(sum_user_assoc)\n",
        "        reward_ind = np.zeros(np.size(sum_user_assoc))\n",
        "        reward = 0\n",
        "        for k in range(self.NUM_UAV):\n",
        "            if k == jammed_uav_index:\n",
        "                continue\n",
        "            if self.flag[k] != 0:\n",
        "                # Only penalized if the respective UAV is out of bound\n",
        "                sum_user_assoc_temp[k] -= 2\n",
        "                reward_ind[k] = np.average(sum_user_assoc_temp)\n",
        "                isDone = True\n",
        "            else:\n",
        "                reward_ind[k] = np.average(sum_user_assoc)\n",
        "        reward = np.copy(reward_ind)\n",
        "\n",
        "\n",
        "\n",
        "        # Return of obs, reward, done, info\n",
        "        return np.copy(self.state), reward, isDone, \"empty\", np.sum(sum_user_assoc)\n",
        "\n",
        "    # Render Function\n",
        "    def render(self, ax, mode='animation', close=False):\n",
        "        # Implement viz\n",
        "        if mode == 'animation':\n",
        "            ax.cla()\n",
        "            position = self.state[:, 0:2] * self.grid_space\n",
        "\n",
        "            # Define colors for different regions\n",
        "            region_colors = {\n",
        "                0: '#CB4335',\n",
        "                1: '#7D3C98',\n",
        "                2: '#2E86C1',\n",
        "                3: '#28B463',\n",
        "                4: '#F1C40F'\n",
        "            }\n",
        "            # Define markers for different UAVs\n",
        "            markers = ['x', 'p', 's', '^', 'd']\n",
        "            # Plot users with label \"Users\" for all regions\n",
        "            for region, color in region_colors.items():\n",
        "                ax.scatter(self.u_loc[self.u_loc[:, 2] == region, 0], self.u_loc[self.u_loc[:, 2] == region, 1], c=color,\n",
        "                          marker='o', label=\"Users\")\n",
        "            #ax.scatter(position[:, 0], position[:, 1], c='#000000', marker='x', label=\"UAV\")\n",
        "            for i, (x, y) in enumerate(position):\n",
        "                cc = plt.Circle((x, y), self.coverage_radius, alpha=0.1)\n",
        "                ax.set_aspect(1)\n",
        "                ax.add_artist(cc)\n",
        "                ax.scatter(x, y, c='black', marker=markers[i], label=f\"UAV {i+1}\")\n",
        "            ax.set_xlim(-50, 1050)\n",
        "            ax.set_ylim(-50, 1050)\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        # reset out states\n",
        "        self.state[:, 0:4] = [[0, 0, 0.0, 0.0], [0, 0, 0.0, 0.0], [0, 0, 0.0, 0.0], [0, 0, 0.0, 0.0], [0, 0, 0.0, 0.0]]\n",
        "        return self.state\n",
        "\n",
        "    def get_state(self):\n",
        "        state_loc = np.zeros((self.NUM_UAV, 4))\n",
        "        for k in range(self.NUM_UAV):\n",
        "            state_loc[k, 0] = self.state[k, 0]\n",
        "            state_loc[k, 1] = self.state[k, 1]\n",
        "            state_loc[k, 2] = self.state[k, 2]\n",
        "            state_loc[k, 3] = self.state[k, 3]\n",
        "        return state_loc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rpSJL7-0YKd"
      },
      "outputs": [],
      "source": [
        "# Extended version of render function to plot best state and final state of the UAVs\n",
        "env=UAVenv()\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import math\n",
        "\n",
        "def final_render(state, remark):\n",
        "    USER_LOC = np.loadtxt('UserLocationNew.txt', dtype=np.int32, delimiter=' ')\n",
        "    u_loc = USER_LOC\n",
        "    fig = plt.figure()\n",
        "    gs = GridSpec(1, 1, figure=fig)\n",
        "    ax = fig.add_subplot(gs[0:1, 0:1])\n",
        "    grid_space = 100\n",
        "    UAV_HEIGHT = 350\n",
        "    THETA = 60 * math.pi / 180\n",
        "    coverage_radius = UAV_HEIGHT * np.tan(THETA / 2)\n",
        "\n",
        "    ax.cla()\n",
        "    position = state[:, 0:2] * grid_space\n",
        "\n",
        "    # Define colors for different regions\n",
        "    region_colors = {\n",
        "        0: '#CB4335',\n",
        "        1: '#7D3C98',\n",
        "        2: '#2E86C1',\n",
        "        3: '#28B463',\n",
        "        4: '#F1C40F'\n",
        "    }\n",
        "\n",
        "    # Define markers for different UAVs\n",
        "    markers = ['x', 'p', 's', '^', 'd']\n",
        "    # Plot users with label \"Users\" for all regions\n",
        "    for region, color in region_colors.items():\n",
        "        ax.scatter(u_loc[u_loc[:,2] == region, 0], u_loc[u_loc[:,2] == region, 1], c = color, marker='o', label = \"Users\")\n",
        "\n",
        "    #ax.scatter(position[:, 0], position[:, 1], c = '#000000', marker='x', label = \"UAV\")\n",
        "    for i, (x, y) in enumerate(position):\n",
        "        cc = plt.Circle((x, y), coverage_radius, alpha=0.1)\n",
        "        ax.set_aspect(1)\n",
        "        ax.add_artist(cc)\n",
        "        ax.scatter(x, y, c='black', marker=markers[i], label=f\"UAV {i+1}\")\n",
        "    #ax.legend()\n",
        "    if remark == \"best\":\n",
        "        plt.title(\"Best state of UAV\")\n",
        "    elif remark == \"final\":\n",
        "        plt.title(\"Final state of UAV\")\n",
        "    plt.pause(0.5)\n",
        "    plt.xlim(-50, 1050)\n",
        "    plt.ylim(-50, 1050)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "_BgcIEjc0f96",
        "outputId": "a392f170-6cc1-4252-ffa9-4d9c18fa3734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9ff3a7e25b3e>\u001b[0m in \u001b[0;36m<cell line: 152>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_UAV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUAV_OB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mUAV_OB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-9ff3a7e25b3e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mminibatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0mminibatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m       \u001b[0mminibatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Main Function\n",
        "\n",
        "from ast import Num\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import torch\n",
        "from torch import Tensor, nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import IterableDataset\n",
        "import os\n",
        "from scipy.io import savemat\n",
        "\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
        "\n",
        "SEED = 1\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "## GPU configuration use for faster processing\n",
        "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cpu\"\n",
        "\n",
        "\n",
        "# DNN modeling\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.linear_stack = model = nn.Sequential(\n",
        "            nn.Linear(self.state_size,400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400,400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400, self.action_size)\n",
        "        ).to(device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        Q_values = self.linear_stack(x)\n",
        "        return Q_values\n",
        "\n",
        "class DQL:\n",
        "    # Initializing a Deep Neural Network\n",
        "    def __init__(self):\n",
        "        self.state_size = 4\n",
        "        self.action_size = 5\n",
        "        self.replay_buffer = deque(maxlen = 125000)\n",
        "        self.gamma = discount_factor\n",
        "        self.epsilon = epsilon\n",
        "        self.learning_rate = alpha\n",
        "        self.main_network = NeuralNetwork(self.state_size, self.action_size).to(device)\n",
        "        self.target_network = NeuralNetwork(self.state_size, self.action_size).to(device)\n",
        "        self.target_network.load_state_dict(self.main_network.state_dict())\n",
        "        self.optimizer = torch.optim.Adam(self.main_network.parameters(), lr = self.learning_rate)\n",
        "        self.loss_func = nn.SmoothL1Loss()      # Huber Loss // Combines MSE and MAE\n",
        "        self.steps_done = 0\n",
        "\n",
        "    # Storing information of individual UAV information in their respective buffer\n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "\n",
        "    # Deployment of epsilon greedy policy\n",
        "    def epsilon_greedy(self, state):\n",
        "        temp = random.random()\n",
        "        self.steps_done += 1\n",
        "        if temp <= self.epsilon:\n",
        "            action = torch.tensor([[np.random.randint(0, 4)]], device = device, dtype = torch.long)\n",
        "        else:\n",
        "            state = torch.unsqueeze(torch.FloatTensor(state),0)\n",
        "            Q_values = self.main_network(state)\n",
        "            action = Q_values.max(1)[1].view(1,1)\n",
        "        return action\n",
        "\n",
        "    # Training of the DNN\n",
        "    def train(self,batch_size):\n",
        "      minibatch = random.sample(self.replay_buffer, batch_size)\n",
        "      minibatch = np.array(minibatch,dtype=object)\n",
        "      minibatch = minibatch.reshape(batch_size,5)\n",
        "      state = torch.FloatTensor(np.vstack(minibatch[:,0]))\n",
        "      action = torch.LongTensor(np.vstack(minibatch[:,1]))\n",
        "      reward = torch.FloatTensor(np.vstack(minibatch[:,2]))\n",
        "      next_state = torch.FloatTensor(np.vstack(minibatch[:,3]))\n",
        "      done = torch.Tensor(np.vstack(minibatch[:,4]))\n",
        "      state = state.to(device = device)\n",
        "      action = action.to(device = device)\n",
        "      reward = reward.to(device = device)\n",
        "      next_state = next_state.to(device = device)\n",
        "      done = done.to(device = device)\n",
        "\n",
        "      Q_next = self.target_network(next_state).detach()\n",
        "      target_Q = reward.cpu().squeeze() + self.gamma * Q_next.cpu().max(1)[0].view(batch_size, 1).squeeze() * (\n",
        "                1 - np.array([state[e].cpu().mean() == next_state[e].cpu().mean() for e in range(len(next_state))])\n",
        "            )\n",
        "\n",
        "      # Forward\n",
        "      # Loss calculation based on loss function\n",
        "      target_Q = target_Q.float()\n",
        "      Q_main = self.main_network(state).gather(1, action).squeeze()\n",
        "      loss = self.loss_func(target_Q.cpu().detach(), Q_main.cpu())\n",
        "      # Backward\n",
        "      self.optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      # For gradient clipping\n",
        "      for param in self.main_network.parameters():\n",
        "          param.grad.data.clamp_(-1,1)\n",
        "      # Gradient descent\n",
        "      self.optimizer.step()\n",
        "\n",
        "\n",
        "u_env = UAVenv()\n",
        "GRID_SIZE = u_env.GRID_SIZE\n",
        "NUM_UAV = u_env.NUM_UAV\n",
        "NUM_USER = u_env.NUM_USER\n",
        "num_episode = 750\n",
        "num_epochs = 100\n",
        "discount_factor = 0.95\n",
        "alpha = 3.5e-4\n",
        "batch_size = 512\n",
        "update_rate = 10  #50\n",
        "epsilon = 0.10\n",
        "random.seed(SEED)\n",
        "\n",
        "\n",
        "\n",
        "# Keeping track of the episode reward\n",
        "episode_reward = np.zeros(num_episode)\n",
        "episode_user_connected = np.zeros(num_episode)\n",
        "\n",
        "fig = plt.figure()\n",
        "gs = GridSpec(1, 1, figure=fig)\n",
        "ax1 = fig.add_subplot(gs[0:1, 0:1])\n",
        "\n",
        "#creating object for 5 UAVs\n",
        "UAV_OB = [None, None, None, None, None]\n",
        "\n",
        "\n",
        "for k in range(NUM_UAV):\n",
        "            UAV_OB[k] = DQL()\n",
        "best_result = 0\n",
        "\n",
        "for i_episode in range(num_episode):\n",
        "    print(i_episode)\n",
        "\n",
        "    # Environment reset and get the states\n",
        "    u_env.reset()\n",
        "\n",
        "    # Get the initial states\n",
        "    states = u_env.get_state()\n",
        "    reward = np.zeros(NUM_UAV)\n",
        "\n",
        "\n",
        "    for t in range(num_epochs):\n",
        "        drone_act_list = []\n",
        "        # Update the target network\n",
        "        for k in range(NUM_UAV):\n",
        "            if t % update_rate == 0:\n",
        "                UAV_OB[k].target_network.load_state_dict(UAV_OB[k].main_network.state_dict())\n",
        "\n",
        "        # Determining the actions for all drones\n",
        "        states_ten = torch.from_numpy(states)\n",
        "        for k in range(NUM_UAV):\n",
        "            state = states_ten[k, :]\n",
        "            action = UAV_OB[k].epsilon_greedy(state.float())\n",
        "            drone_act_list.append(action)\n",
        "\n",
        "\n",
        "        # Find the global reward for the combined set of actions for the UAV\n",
        "        temp_data = u_env.step(drone_act_list, reward)\n",
        "        reward = temp_data[1]\n",
        "        done = temp_data[2]\n",
        "        next_state = u_env.get_state()\n",
        "\n",
        "        # Store the transition information\n",
        "        for k in range(NUM_UAV):\n",
        "            ## Storing of the information on the individual UAV and it's reward value in itself.\n",
        "            state = states_ten[k, :]\n",
        "            action = drone_act_list[k]\n",
        "            next_sta = next_state[k, :]\n",
        "            reward_ind = reward[k]\n",
        "            UAV_OB[k].store_transition(state, action, reward_ind, next_sta, done)\n",
        "\n",
        "        # Calculation of the total episodic reward of all the UAVs\n",
        "        # Calculation of the total number of connected User for the combination of all UAVs\n",
        "        episode_reward[i_episode] += sum(reward)\n",
        "        episode_user_connected[i_episode] += temp_data[4]\n",
        "\n",
        "        states = next_state\n",
        "\n",
        "        for k in range(NUM_UAV):\n",
        "            if len(UAV_OB[k].replay_buffer) > batch_size:\n",
        "                UAV_OB[k].train(batch_size)\n",
        "\n",
        "\n",
        "\n",
        "# Assuming you have trained models in UAV_OB\n",
        "for k in range(NUM_UAV):\n",
        "    model_path = f'model_UAV_{k}.pth'\n",
        "    torch.save(UAV_OB[k].main_network.state_dict(), model_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "# Create DQL objects for testing\n",
        "UAV_OB_test = [DQL() for _ in range(NUM_UAV)]\n",
        "\n",
        "# Load the saved models for testing\n",
        "for k in range(NUM_UAV):\n",
        "    model_path = f'model_UAV_{k}.pth'\n",
        "    UAV_OB_test[k].main_network.load_state_dict(torch.load(model_path))\n",
        "    UAV_OB_test[k].main_network.eval()  # Set the model to evaluation mode\n",
        "\n",
        "\n",
        "# Reset the environment for testing\n",
        "u_env.reset()\n",
        "jammed_uav_index = None\n",
        "# Get the initial states\n",
        "states = u_env.get_state()\n",
        "episode_states = []\n",
        "for t in range(100):\n",
        "    drone_act_list = []\n",
        "    if t >= 30:  # Jam a UAV after 25 epochs\n",
        "        jammed_uav_index = 3\n",
        "    # Use the loaded models to make decisions\n",
        "    for k in range(NUM_UAV):\n",
        "        if k != jammed_uav_index:\n",
        "            state = states[k, :]\n",
        "            state = torch.unsqueeze(torch.FloatTensor(state), 0)\n",
        "            with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "                Q_values = UAV_OB_test[k].main_network(state.float())\n",
        "            best_next_action = torch.max(Q_values.cpu(), 1)[1].data.numpy()\n",
        "            best_next_action = best_next_action[0]\n",
        "            drone_act_list.append(best_next_action)\n",
        "        else:\n",
        "            drone_act_list.append(4)  # Hover action for the jammed UAV\n",
        "        # Step in the environment with the chosen actions\n",
        "    temp_data = u_env.step(drone_act_list, reward,jammed_uav_index)\n",
        "    states = u_env.get_state()\n",
        "    states_fin = states\n",
        "\n",
        "    episode_states.append(states_fin.tolist())\n",
        "\n",
        "def animate(i):\n",
        "    ax1.clear()\n",
        "    u_env.state = np.array(episode_states[i])  # Set the environment state to the current episode state\n",
        "    u_env.render(ax1, mode='animation')\n",
        "    #ax1.set_title(\"Intermediate state of UAV in episode {}\".format(i_episode))\n",
        "\n",
        "ani = animation.FuncAnimation(fig, animate, frames=len(episode_states), interval=200, blit=False)\n",
        "\n",
        "# Save the animation as an MP4 video file\n",
        "ani.save('animation_episode_{}.mp4', writer='ffmpeg')\n",
        "print(\"Number of user connected is: \", temp_data[4])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48q1yz7YaNlz",
        "outputId": "dc084c86-d344-4f7b-a635-e7dad8f6ca71"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of user connected is:  76\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}